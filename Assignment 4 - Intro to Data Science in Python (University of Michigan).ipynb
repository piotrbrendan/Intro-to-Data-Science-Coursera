{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Hypothesis Testing\n",
    "This assignment requires more individual learning than previous assignments - you are encouraged to check out the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/) to find functions or methods you might not have used yet, or ask questions on [Stack Overflow](http://stackoverflow.com/) and tag them as pandas and python related. And of course, the discussion forums are open for interaction with your peers and the course staff.\n",
    "\n",
    "Definitions:\n",
    "* A _quarter_ is a specific three month period, Q1 is January through March, Q2 is April through June, Q3 is July through September, Q4 is October through December.\n",
    "* A _recession_ is defined as starting with two consecutive quarters of GDP decline, and ending with two consecutive quarters of GDP growth.\n",
    "* A _recession bottom_ is the quarter within a recession which had the lowest GDP.\n",
    "* A _university town_ is a city which has a high percentage of university students compared to the total population of the city.\n",
    "\n",
    "**Hypothesis**: University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom. (`price_ratio=quarter_before_recession/recession_bottom`)\n",
    "\n",
    "The following data files are available for this assignment:\n",
    "* From the [Zillow research data site](http://www.zillow.com/research/data/) there is housing data for the United States. In particular the datafile for [all homes at a city level](http://files.zillowstatic.com/research/public/City/City_Zhvi_AllHomes.csv), ```City_Zhvi_AllHomes.csv```, has median home sale prices at a fine grained level.\n",
    "* From the Wikipedia page on college towns is a list of [university towns in the United States](https://en.wikipedia.org/wiki/List_of_college_towns#College_towns_in_the_United_States) which has been copy and pasted into the file ```university_towns.txt```.\n",
    "* From Bureau of Economic Analysis, US Department of Commerce, the [GDP over time](http://www.bea.gov/national/index.htm#gdp) of the United States in current dollars (use the chained value in 2009 dollars), in quarterly intervals, in the file ```gdplev.xls```. For this assignment, only look at GDP data from the first quarter of 2000 onward.\n",
    "\n",
    "Each function in this assignment below is worth 10%, with the exception of ```run_ttest()```, which is worth 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and cleaning data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### University Towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auburn (Auburn University)[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florence (University of North Alabama)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jacksonville (Jacksonville State University)[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Livingston (University of West Alabama)[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Montevallo (University of Montevallo)[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Troy (Troy University)[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuscaloosa (University of Alabama, Stillman Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuskegee (Tuskegee University)[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alaska[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fairbanks (University of Alaska Fairbanks)[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arizona[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Flagstaff (Northern Arizona University)[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tempe (Arizona State University)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tucson (University of Arizona)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           RegionName\n",
       "0                                       Alabama[edit]\n",
       "1                       Auburn (Auburn University)[1]\n",
       "2              Florence (University of North Alabama)\n",
       "3     Jacksonville (Jacksonville State University)[2]\n",
       "4          Livingston (University of West Alabama)[2]\n",
       "5            Montevallo (University of Montevallo)[2]\n",
       "6                           Troy (Troy University)[2]\n",
       "7   Tuscaloosa (University of Alabama, Stillman Co...\n",
       "8                   Tuskegee (Tuskegee University)[5]\n",
       "9                                        Alaska[edit]\n",
       "10      Fairbanks (University of Alaska Fairbanks)[2]\n",
       "11                                      Arizona[edit]\n",
       "12         Flagstaff (Northern Arizona University)[6]\n",
       "13                   Tempe (Arizona State University)\n",
       "14                     Tucson (University of Arizona)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utowns = pd.read_fwf('university_towns.txt',header = None)\n",
    "Utowns.columns = ['RegionName']\n",
    "Utowns.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that college towns are mixed with States - we have to clean it up and separate states from uni towns in the first run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 9, 11, 15, 24, 50, 60, 68, 71, 84],\n",
       " ['Alabama',\n",
       "  'Alaska',\n",
       "  'Arizona',\n",
       "  'Arkansas',\n",
       "  'California',\n",
       "  'Colorado',\n",
       "  'Connecticut',\n",
       "  'Delaware',\n",
       "  'Florida',\n",
       "  'Georgia'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### searching for index and name of states in Utowns\n",
    "state_idx = []\n",
    "state_name= []\n",
    "for i,state in enumerate(Utowns['RegionName']):\n",
    "    if '[edit]' in state:\n",
    "        state_idx.append(i)\n",
    "        state = state[:state.rfind('[')] #cleaning state name by erasing '[edit]' part from string\n",
    "        state_name.append(state)\n",
    "        \n",
    "### adding last index to bins in state_idx        \n",
    "state_idx.append(len(Utowns))\n",
    "\n",
    "state_idx[:10],state_name[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have indexes for every state and cleaned name of states. Next step is to construct Data Frame, with the\n",
    "following format:\n",
    "    \n",
    "    DataFrame( [ [\"Michigan\", \"Ann Arbor\"], [\"Michigan\", \"Yipsilanti\"] ], \n",
    "    columns=[\"State\", \"RegionName\"]  )\n",
    "    \n",
    "Every region will have corresponding state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### using cut function to create new col with state name\n",
    "Utowns['state_idx'] = pd.cut(Utowns.index,state_idx,right=False,include_lowest=True,labels = state_name)        \n",
    "Utowns.rename(columns = {'state_idx':'State'},inplace=True)    \n",
    "Utowns = Utowns[['State','RegionName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining cleaning function to get rid of every character after '(', for example:<br>\n",
    "in: Troy (Troy University)<br>\n",
    "out: Troy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_fun(char):\n",
    "    \n",
    "    if char.rfind('(') != -1:\n",
    "        char = char[:char.rfind('(')-1]\n",
    "    return char    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama[edit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State     RegionName\n",
       "0  Alabama  Alabama[edit]\n",
       "1  Alabama         Auburn\n",
       "2  Alabama       Florence"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### cleaning RegionName col\n",
    "Utowns['RegionName'] = Utowns['RegionName'].map(clean_fun)\n",
    "Utowns.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### choosing regions that are not states (row selection)\n",
    "Utowns = Utowns[Utowns.index.isin(state_idx[:-1]) == False]\n",
    "Utowns = Utowns.reset_index(drop=True)\n",
    "\n",
    "Utowns['RegionName'] = Utowns['RegionName'].astype(object) \n",
    "Utowns['State'] =  Utowns['State'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After few manipulations above we have DataFrame with university town and its state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Troy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Tuscaloosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State    RegionName\n",
       "0  Alabama        Auburn\n",
       "1  Alabama      Florence\n",
       "2  Alabama  Jacksonville\n",
       "3  Alabama    Livingston\n",
       "4  Alabama    Montevallo\n",
       "5  Alabama          Troy\n",
       "6  Alabama    Tuscaloosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utowns.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Housing_df = pd.read_csv('City_Zhvi_AllHomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>1996-07</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Queens</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>644300</td>\n",
       "      <td>655300</td>\n",
       "      <td>667800</td>\n",
       "      <td>677500</td>\n",
       "      <td>683400</td>\n",
       "      <td>688300</td>\n",
       "      <td>694800</td>\n",
       "      <td>701900</td>\n",
       "      <td>707700</td>\n",
       "      <td>710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12447</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>2</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>154600.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>154200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>621700</td>\n",
       "      <td>626600</td>\n",
       "      <td>630200</td>\n",
       "      <td>632500</td>\n",
       "      <td>633800</td>\n",
       "      <td>636700</td>\n",
       "      <td>642100</td>\n",
       "      <td>647600</td>\n",
       "      <td>653500</td>\n",
       "      <td>658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17426</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>3</td>\n",
       "      <td>109700.0</td>\n",
       "      <td>109400.0</td>\n",
       "      <td>109300.0</td>\n",
       "      <td>109300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>219500</td>\n",
       "      <td>220000</td>\n",
       "      <td>220300</td>\n",
       "      <td>220400</td>\n",
       "      <td>220800</td>\n",
       "      <td>221500</td>\n",
       "      <td>221700</td>\n",
       "      <td>221400</td>\n",
       "      <td>220900</td>\n",
       "      <td>221000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID   RegionName State                           Metro   CountyName  \\\n",
       "0      6181     New York    NY                        New York       Queens   \n",
       "1     12447  Los Angeles    CA  Los Angeles-Long Beach-Anaheim  Los Angeles   \n",
       "2     17426      Chicago    IL                         Chicago         Cook   \n",
       "\n",
       "   SizeRank   1996-04   1996-05   1996-06   1996-07   ...     2017-03  \\\n",
       "0         1       NaN       NaN       NaN       NaN   ...      644300   \n",
       "1         2  155000.0  154600.0  154400.0  154200.0   ...      621700   \n",
       "2         3  109700.0  109400.0  109300.0  109300.0   ...      219500   \n",
       "\n",
       "   2017-04  2017-05  2017-06  2017-07  2017-08  2017-09  2017-10  2017-11  \\\n",
       "0   655300   667800   677500   683400   688300   694800   701900   707700   \n",
       "1   626600   630200   632500   633800   636700   642100   647600   653500   \n",
       "2   220000   220300   220400   220800   221500   221700   221400   220900   \n",
       "\n",
       "   2017-12  \n",
       "0   710300  \n",
       "1   658500  \n",
       "2   221000  \n",
       "\n",
       "[3 rows x 267 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Housing_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we need to convert State abbreviations to its full names to match it with Utowns DataFrame (we will use RegionName and State columns in Utowns and Housing_df as keys to merge both tables later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### converting states abbreviations to its full names:\n",
    "### dictionary with mapping from abbreviation to state full name\n",
    "states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 'NA': 'National', \n",
    "          'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', \n",
    "          'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', \n",
    "          'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', \n",
    "          'HI': 'Hawaii', 'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', \n",
    "          'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina',\n",
    "          'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', \n",
    "          'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', \n",
    "          'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas', 'NY': 'New York', \n",
    "          'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California', 'CO': 'Colorado',\n",
    "          'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island',\n",
    "          'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts',\n",
    "          'GA': 'Georgia', 'ND': 'North Dakota', 'VA': 'Virginia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Housing_df['State'] = [states[x] for x in Housing_df['State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        New York\n",
       "1      California\n",
       "2        Illinois\n",
       "3    Pennsylvania\n",
       "4         Arizona\n",
       "Name: State, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Housing_df['State'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State and RegionName will be set as an index <br>\n",
    "From 4th column on, there are consecutive months with house price indices starting from 04-1996 <br>\n",
    "We have to transform monthly to quarterly periods, we will use mean function as an aggregating funcition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing_df = Housing_df.set_index(['State','RegionName'])\n",
    "Housing_dfQ = Housing_df.iloc[:,4:].groupby(pd.PeriodIndex(Housing_df.columns[4:], freq='Q'), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1996Q2</th>\n",
       "      <th>1996Q3</th>\n",
       "      <th>1996Q4</th>\n",
       "      <th>1997Q1</th>\n",
       "      <th>1997Q2</th>\n",
       "      <th>1997Q3</th>\n",
       "      <th>1997Q4</th>\n",
       "      <th>1998Q1</th>\n",
       "      <th>1998Q2</th>\n",
       "      <th>1998Q3</th>\n",
       "      <th>...</th>\n",
       "      <th>2015Q3</th>\n",
       "      <th>2015Q4</th>\n",
       "      <th>2016Q1</th>\n",
       "      <th>2016Q2</th>\n",
       "      <th>2016Q3</th>\n",
       "      <th>2016Q4</th>\n",
       "      <th>2017Q1</th>\n",
       "      <th>2017Q2</th>\n",
       "      <th>2017Q3</th>\n",
       "      <th>2017Q4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>New York</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>557166.7</td>\n",
       "      <td>569266.7</td>\n",
       "      <td>579900.0</td>\n",
       "      <td>589033.3</td>\n",
       "      <td>601966.7</td>\n",
       "      <td>617833.3</td>\n",
       "      <td>635433.3</td>\n",
       "      <td>666866.7</td>\n",
       "      <td>688833.3</td>\n",
       "      <td>706633.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>154666.7</td>\n",
       "      <td>154200.0</td>\n",
       "      <td>154433.3</td>\n",
       "      <td>156866.7</td>\n",
       "      <td>158533.3</td>\n",
       "      <td>159266.7</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>166966.7</td>\n",
       "      <td>171400.0</td>\n",
       "      <td>175966.7</td>\n",
       "      <td>...</td>\n",
       "      <td>543433.3</td>\n",
       "      <td>554266.7</td>\n",
       "      <td>565700.0</td>\n",
       "      <td>579633.3</td>\n",
       "      <td>588666.7</td>\n",
       "      <td>602133.3</td>\n",
       "      <td>616066.7</td>\n",
       "      <td>629766.7</td>\n",
       "      <td>637533.3</td>\n",
       "      <td>653200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <th>Chicago</th>\n",
       "      <td>109466.7</td>\n",
       "      <td>109133.3</td>\n",
       "      <td>109600.0</td>\n",
       "      <td>111266.7</td>\n",
       "      <td>112200.0</td>\n",
       "      <td>112966.7</td>\n",
       "      <td>114833.3</td>\n",
       "      <td>116966.7</td>\n",
       "      <td>118433.3</td>\n",
       "      <td>120700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200566.7</td>\n",
       "      <td>202133.3</td>\n",
       "      <td>203200.0</td>\n",
       "      <td>204966.7</td>\n",
       "      <td>207066.7</td>\n",
       "      <td>211866.7</td>\n",
       "      <td>218466.7</td>\n",
       "      <td>220233.3</td>\n",
       "      <td>221333.3</td>\n",
       "      <td>221100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          1996Q2    1996Q3    1996Q4    1997Q1    1997Q2  \\\n",
       "State      RegionName                                                      \n",
       "New York   New York          NaN       NaN       NaN       NaN       NaN   \n",
       "California Los Angeles  154666.7  154200.0  154433.3  156866.7  158533.3   \n",
       "Illinois   Chicago      109466.7  109133.3  109600.0  111266.7  112200.0   \n",
       "\n",
       "                          1997Q3    1997Q4    1998Q1    1998Q2    1998Q3  \\\n",
       "State      RegionName                                                      \n",
       "New York   New York          NaN       NaN       NaN       NaN       NaN   \n",
       "California Los Angeles  159266.7  162000.0  166966.7  171400.0  175966.7   \n",
       "Illinois   Chicago      112966.7  114833.3  116966.7  118433.3  120700.0   \n",
       "\n",
       "                          ...       2015Q3    2015Q4    2016Q1    2016Q2  \\\n",
       "State      RegionName     ...                                              \n",
       "New York   New York       ...     557166.7  569266.7  579900.0  589033.3   \n",
       "California Los Angeles    ...     543433.3  554266.7  565700.0  579633.3   \n",
       "Illinois   Chicago        ...     200566.7  202133.3  203200.0  204966.7   \n",
       "\n",
       "                          2016Q3    2016Q4    2017Q1    2017Q2    2017Q3  \\\n",
       "State      RegionName                                                      \n",
       "New York   New York     601966.7  617833.3  635433.3  666866.7  688833.3   \n",
       "California Los Angeles  588666.7  602133.3  616066.7  629766.7  637533.3   \n",
       "Illinois   Chicago      207066.7  211866.7  218466.7  220233.3  221333.3   \n",
       "\n",
       "                          2017Q4  \n",
       "State      RegionName             \n",
       "New York   New York     706633.3  \n",
       "California Los Angeles  653200.0  \n",
       "Illinois   Chicago      221100.0  \n",
       "\n",
       "[3 rows x 87 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Housing_dfQ.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance with task in this assignment, we are interested with periods from 2000Q1 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing_dfQ = Housing_dfQ.loc[:,'2000Q1':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2000Q1</th>\n",
       "      <th>2000Q2</th>\n",
       "      <th>2000Q3</th>\n",
       "      <th>2000Q4</th>\n",
       "      <th>2001Q1</th>\n",
       "      <th>2001Q2</th>\n",
       "      <th>2001Q3</th>\n",
       "      <th>2001Q4</th>\n",
       "      <th>2002Q1</th>\n",
       "      <th>2002Q2</th>\n",
       "      <th>...</th>\n",
       "      <th>2015Q3</th>\n",
       "      <th>2015Q4</th>\n",
       "      <th>2016Q1</th>\n",
       "      <th>2016Q2</th>\n",
       "      <th>2016Q3</th>\n",
       "      <th>2016Q4</th>\n",
       "      <th>2017Q1</th>\n",
       "      <th>2017Q2</th>\n",
       "      <th>2017Q3</th>\n",
       "      <th>2017Q4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>New York</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>557166.7</td>\n",
       "      <td>569266.7</td>\n",
       "      <td>579900.0</td>\n",
       "      <td>589033.3</td>\n",
       "      <td>601966.7</td>\n",
       "      <td>617833.3</td>\n",
       "      <td>635433.3</td>\n",
       "      <td>666866.7</td>\n",
       "      <td>688833.3</td>\n",
       "      <td>706633.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>207066.7</td>\n",
       "      <td>214466.7</td>\n",
       "      <td>220966.7</td>\n",
       "      <td>226166.7</td>\n",
       "      <td>233033.3</td>\n",
       "      <td>239100.0</td>\n",
       "      <td>245066.7</td>\n",
       "      <td>253033.3</td>\n",
       "      <td>261966.7</td>\n",
       "      <td>272700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>543433.3</td>\n",
       "      <td>554266.7</td>\n",
       "      <td>565700.0</td>\n",
       "      <td>579633.3</td>\n",
       "      <td>588666.7</td>\n",
       "      <td>602133.3</td>\n",
       "      <td>616066.7</td>\n",
       "      <td>629766.7</td>\n",
       "      <td>637533.3</td>\n",
       "      <td>653200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <th>Chicago</th>\n",
       "      <td>138400.0</td>\n",
       "      <td>143633.3</td>\n",
       "      <td>147866.7</td>\n",
       "      <td>152133.3</td>\n",
       "      <td>156933.3</td>\n",
       "      <td>161800.0</td>\n",
       "      <td>166400.0</td>\n",
       "      <td>170433.3</td>\n",
       "      <td>175500.0</td>\n",
       "      <td>177566.7</td>\n",
       "      <td>...</td>\n",
       "      <td>200566.7</td>\n",
       "      <td>202133.3</td>\n",
       "      <td>203200.0</td>\n",
       "      <td>204966.7</td>\n",
       "      <td>207066.7</td>\n",
       "      <td>211866.7</td>\n",
       "      <td>218466.7</td>\n",
       "      <td>220233.3</td>\n",
       "      <td>221333.3</td>\n",
       "      <td>221100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>53000.0</td>\n",
       "      <td>53633.3</td>\n",
       "      <td>54133.3</td>\n",
       "      <td>54700.0</td>\n",
       "      <td>55333.3</td>\n",
       "      <td>55533.3</td>\n",
       "      <td>56266.7</td>\n",
       "      <td>57533.3</td>\n",
       "      <td>59133.3</td>\n",
       "      <td>60733.3</td>\n",
       "      <td>...</td>\n",
       "      <td>119700.0</td>\n",
       "      <td>121166.7</td>\n",
       "      <td>123066.7</td>\n",
       "      <td>125633.3</td>\n",
       "      <td>130033.3</td>\n",
       "      <td>131800.0</td>\n",
       "      <td>134666.7</td>\n",
       "      <td>136666.7</td>\n",
       "      <td>139433.3</td>\n",
       "      <td>143566.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <th>Phoenix</th>\n",
       "      <td>111833.3</td>\n",
       "      <td>114366.7</td>\n",
       "      <td>116000.0</td>\n",
       "      <td>117400.0</td>\n",
       "      <td>119600.0</td>\n",
       "      <td>121566.7</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>124300.0</td>\n",
       "      <td>126533.3</td>\n",
       "      <td>128366.7</td>\n",
       "      <td>...</td>\n",
       "      <td>180233.3</td>\n",
       "      <td>184433.3</td>\n",
       "      <td>188800.0</td>\n",
       "      <td>193233.3</td>\n",
       "      <td>198166.7</td>\n",
       "      <td>202433.3</td>\n",
       "      <td>207766.7</td>\n",
       "      <td>212333.3</td>\n",
       "      <td>218266.7</td>\n",
       "      <td>223000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             2000Q1    2000Q2    2000Q3    2000Q4    2001Q1  \\\n",
       "State        RegionName                                                       \n",
       "New York     New York           NaN       NaN       NaN       NaN       NaN   \n",
       "California   Los Angeles   207066.7  214466.7  220966.7  226166.7  233033.3   \n",
       "Illinois     Chicago       138400.0  143633.3  147866.7  152133.3  156933.3   \n",
       "Pennsylvania Philadelphia   53000.0   53633.3   54133.3   54700.0   55333.3   \n",
       "Arizona      Phoenix       111833.3  114366.7  116000.0  117400.0  119600.0   \n",
       "\n",
       "                             2001Q2    2001Q3    2001Q4    2002Q1    2002Q2  \\\n",
       "State        RegionName                                                       \n",
       "New York     New York           NaN       NaN       NaN       NaN       NaN   \n",
       "California   Los Angeles   239100.0  245066.7  253033.3  261966.7  272700.0   \n",
       "Illinois     Chicago       161800.0  166400.0  170433.3  175500.0  177566.7   \n",
       "Pennsylvania Philadelphia   55533.3   56266.7   57533.3   59133.3   60733.3   \n",
       "Arizona      Phoenix       121566.7  122700.0  124300.0  126533.3  128366.7   \n",
       "\n",
       "                             ...       2015Q3    2015Q4    2016Q1    2016Q2  \\\n",
       "State        RegionName      ...                                              \n",
       "New York     New York        ...     557166.7  569266.7  579900.0  589033.3   \n",
       "California   Los Angeles     ...     543433.3  554266.7  565700.0  579633.3   \n",
       "Illinois     Chicago         ...     200566.7  202133.3  203200.0  204966.7   \n",
       "Pennsylvania Philadelphia    ...     119700.0  121166.7  123066.7  125633.3   \n",
       "Arizona      Phoenix         ...     180233.3  184433.3  188800.0  193233.3   \n",
       "\n",
       "                             2016Q3    2016Q4    2017Q1    2017Q2    2017Q3  \\\n",
       "State        RegionName                                                       \n",
       "New York     New York      601966.7  617833.3  635433.3  666866.7  688833.3   \n",
       "California   Los Angeles   588666.7  602133.3  616066.7  629766.7  637533.3   \n",
       "Illinois     Chicago       207066.7  211866.7  218466.7  220233.3  221333.3   \n",
       "Pennsylvania Philadelphia  130033.3  131800.0  134666.7  136666.7  139433.3   \n",
       "Arizona      Phoenix       198166.7  202433.3  207766.7  212333.3  218266.7   \n",
       "\n",
       "                             2017Q4  \n",
       "State        RegionName              \n",
       "New York     New York      706633.3  \n",
       "California   Los Angeles   653200.0  \n",
       "Illinois     Chicago       221100.0  \n",
       "Pennsylvania Philadelphia  143566.7  \n",
       "Arizona      Phoenix       223000.0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Housing_dfQ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US GDP quarterly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After screening gdplev excel file, we can see, that data that is iteresting for is starts from 8th row and from 5th column (so in Python with 4th index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdplev = pd.read_excel('gdplev.xlsx', skiprows = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1929.0</td>\n",
       "      <td>104.6</td>\n",
       "      <td>1056.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1947Q1</td>\n",
       "      <td>243.1</td>\n",
       "      <td>1934.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1930.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>966.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1947Q2</td>\n",
       "      <td>246.3</td>\n",
       "      <td>1932.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1931.0</td>\n",
       "      <td>77.4</td>\n",
       "      <td>904.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1947Q3</td>\n",
       "      <td>250.1</td>\n",
       "      <td>1930.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1  Unnamed: 2  Unnamed: 3 Unnamed: 4  Unnamed: 5  \\\n",
       "0      1929.0       104.6      1056.6         NaN     1947Q1       243.1   \n",
       "1      1930.0        92.2       966.7         NaN     1947Q2       246.3   \n",
       "2      1931.0        77.4       904.8         NaN     1947Q3       250.1   \n",
       "\n",
       "   Unnamed: 6  Unnamed: 7  \n",
       "0      1934.5         NaN  \n",
       "1      1932.3         NaN  \n",
       "2      1930.3         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdplev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdplev = gdplev.iloc[:,[4,6]]\n",
    "gdplev.columns = ['Quarter','GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947Q1</td>\n",
       "      <td>1934.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1947Q2</td>\n",
       "      <td>1932.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1947Q3</td>\n",
       "      <td>1930.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947Q4</td>\n",
       "      <td>1960.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948Q1</td>\n",
       "      <td>1989.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter     GDP\n",
       "0  1947Q1  1934.5\n",
       "1  1947Q2  1932.3\n",
       "2  1947Q3  1930.3\n",
       "3  1947Q4  1960.7\n",
       "4  1948Q1  1989.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdplev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining recession start, recession end and recession bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the hipothesis stated in this assignment that University towns have their mean housing prices less effected by recessions we need to properly find recession periods and measure the price_ratio defined: \n",
    "\n",
    "(price_ratio=quarter_before_recession/recession_bottom)\n",
    "\n",
    "In order to measure price_ratio we need to find:  \n",
    "* recession start date\n",
    "* recession end date\n",
    "* recession bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recession_start_end(series):\n",
    "    ''' returns tuple of two pd.Series, where the first element is recession start Series (with index \n",
    "        and quarter of recession start) and second element is recession end Series (with index and\n",
    "        quarter of recession end)\n",
    "    '''\n",
    "    rec_started = False  #flag whether recession has already started\n",
    "    recession_start=[] \n",
    "    recession_end =[]\n",
    "    \n",
    "    for q in range(2,len(series)-2):\n",
    "        \n",
    "        #check whether recession has started and is not a continuation of ongoing recession:\n",
    "        if (series.iloc[q,1] < series.iloc[q-1,1] < series.iloc[q-2,1]) and (rec_started) == False: \n",
    "            recession_start.append(q)\n",
    "            rec_started = True\n",
    "        \n",
    "        #if recession is ongoing: 'rec_started == True', we check when it has ended:\n",
    "        elif (series.iloc[q,1] < series.iloc[(q+1),1] < series.iloc[(q+2),1]) and (rec_started) == True:\n",
    "            recession_end.append(q+2)\n",
    "            rec_started = False\n",
    "    \n",
    "    rec_start_series = pd.Series(series.iloc[recession_start,0])\n",
    "    rec_end_series = pd.Series(series.iloc[recession_end,0])\n",
    "\n",
    "    return rec_start_series, rec_end_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recession_bottom(series):\n",
    "    ''' returns pd.Series with indexes from 'series' and quarters of recession bottom\n",
    "    '''\n",
    "\n",
    "    start_to_end =  list(zip(rec_start.index,rec_end.index))\n",
    "    rec_bottom_idx = [series.iloc[x[0]:x[1],1].argmin() for x in start_to_end]\n",
    "    rec_bottom = pd.Series(gdplev.iloc[rec_bottom_idx,0])\n",
    "        \n",
    "    return rec_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_start = recession_start_end(gdplev)[0]  \n",
    "rec_end = recession_start_end(gdplev)[1] \n",
    "rec_bottom = recession_bottom(gdplev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      1947Q3\n",
       "9      1949Q2\n",
       "27     1953Q4\n",
       "44     1958Q1\n",
       "92     1970Q1\n",
       "111    1974Q4\n",
       "134    1980Q3\n",
       "176    1991Q1\n",
       "247    2008Q4\n",
       "Name: Quarter, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      1948Q2\n",
       "13     1950Q2\n",
       "30     1954Q3\n",
       "47     1958Q4\n",
       "97     1971Q2\n",
       "114    1975Q3\n",
       "144    1983Q1\n",
       "179    1991Q4\n",
       "251    2009Q4\n",
       "Name: Quarter, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      1947Q3\n",
       "9      1949Q2\n",
       "28     1954Q1\n",
       "44     1958Q1\n",
       "92     1970Q1\n",
       "112    1975Q1\n",
       "134    1980Q3\n",
       "176    1991Q1\n",
       "249    2009Q2\n",
       "Name: Quarter, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the beginnig of XX century there was only 1 recession in US, so we are interested in last element in rec_start, rec_end, rec_bottom series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_rec =  pd.Period(rec_start.iloc[-1])\n",
    "last_before_rec = pd.Period(rec_start.iloc[-1])-1\n",
    "last_bot =  pd.Period(rec_bottom.iloc[-1])\n",
    "last_end = pd.Period(rec_end.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2008Q4</th>\n",
       "      <th>2009Q1</th>\n",
       "      <th>2009Q2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>New York</th>\n",
       "      <td>487,400.0</td>\n",
       "      <td>476,000.0</td>\n",
       "      <td>465,966.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>454,066.7</td>\n",
       "      <td>435,966.7</td>\n",
       "      <td>417,300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <th>Chicago</th>\n",
       "      <td>227,633.3</td>\n",
       "      <td>224,300.0</td>\n",
       "      <td>219,533.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <td>116,866.7</td>\n",
       "      <td>117,133.3</td>\n",
       "      <td>116,433.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <th>Phoenix</th>\n",
       "      <td>185,766.7</td>\n",
       "      <td>177,400.0</td>\n",
       "      <td>167,666.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             2008Q4    2009Q1    2009Q2\n",
       "State        RegionName                                \n",
       "New York     New York     487,400.0 476,000.0 465,966.7\n",
       "California   Los Angeles  454,066.7 435,966.7 417,300.0\n",
       "Illinois     Chicago      227,633.3 224,300.0 219,533.3\n",
       "Pennsylvania Philadelphia 116,866.7 117,133.3 116,433.3\n",
       "Arizona      Phoenix      185,766.7 177,400.0 167,666.7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "Housing_dfQ.loc[:,last_rec:last_bot].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to merge Utowns and Housing_dfQ frames to get index values for uni towns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Utowns_prices = pd.merge(Utowns, Housing_dfQ, how='left',left_on=['State','RegionName'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>2000Q1</th>\n",
       "      <th>2000Q2</th>\n",
       "      <th>2000Q3</th>\n",
       "      <th>2000Q4</th>\n",
       "      <th>2001Q1</th>\n",
       "      <th>2001Q2</th>\n",
       "      <th>2001Q3</th>\n",
       "      <th>2001Q4</th>\n",
       "      <th>...</th>\n",
       "      <th>2015Q3</th>\n",
       "      <th>2015Q4</th>\n",
       "      <th>2016Q1</th>\n",
       "      <th>2016Q2</th>\n",
       "      <th>2016Q3</th>\n",
       "      <th>2016Q4</th>\n",
       "      <th>2017Q1</th>\n",
       "      <th>2017Q2</th>\n",
       "      <th>2017Q3</th>\n",
       "      <th>2017Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>157,266.7</td>\n",
       "      <td>159,066.7</td>\n",
       "      <td>157,666.7</td>\n",
       "      <td>157,133.3</td>\n",
       "      <td>156,533.3</td>\n",
       "      <td>162,466.7</td>\n",
       "      <td>168,466.7</td>\n",
       "      <td>171,100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>213,733.3</td>\n",
       "      <td>215,500.0</td>\n",
       "      <td>217,700.0</td>\n",
       "      <td>221,433.3</td>\n",
       "      <td>223,966.7</td>\n",
       "      <td>226,033.3</td>\n",
       "      <td>232,566.7</td>\n",
       "      <td>237,466.7</td>\n",
       "      <td>239,466.7</td>\n",
       "      <td>241,533.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "      <td>75,566.7</td>\n",
       "      <td>76,233.3</td>\n",
       "      <td>77,333.3</td>\n",
       "      <td>76,633.3</td>\n",
       "      <td>77,800.0</td>\n",
       "      <td>78,700.0</td>\n",
       "      <td>78,700.0</td>\n",
       "      <td>78,900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101,633.3</td>\n",
       "      <td>102,533.3</td>\n",
       "      <td>102,600.0</td>\n",
       "      <td>104,066.7</td>\n",
       "      <td>105,200.0</td>\n",
       "      <td>105,866.7</td>\n",
       "      <td>106,433.3</td>\n",
       "      <td>108,633.3</td>\n",
       "      <td>110,166.7</td>\n",
       "      <td>111,233.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "      <td>97,000.0</td>\n",
       "      <td>96,800.0</td>\n",
       "      <td>96,533.3</td>\n",
       "      <td>98,333.3</td>\n",
       "      <td>99,466.7</td>\n",
       "      <td>101,333.3</td>\n",
       "      <td>103,200.0</td>\n",
       "      <td>101,866.7</td>\n",
       "      <td>...</td>\n",
       "      <td>123,200.0</td>\n",
       "      <td>124,033.3</td>\n",
       "      <td>124,866.7</td>\n",
       "      <td>124,600.0</td>\n",
       "      <td>123,000.0</td>\n",
       "      <td>124,000.0</td>\n",
       "      <td>127,133.3</td>\n",
       "      <td>129,500.0</td>\n",
       "      <td>131,833.3</td>\n",
       "      <td>132,433.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State    RegionName    2000Q1    2000Q2    2000Q3    2000Q4    2001Q1  \\\n",
       "0  Alabama        Auburn 157,266.7 159,066.7 157,666.7 157,133.3 156,533.3   \n",
       "1  Alabama      Florence  75,566.7  76,233.3  77,333.3  76,633.3  77,800.0   \n",
       "2  Alabama  Jacksonville       nan       nan       nan       nan       nan   \n",
       "3  Alabama    Livingston       nan       nan       nan       nan       nan   \n",
       "4  Alabama    Montevallo  97,000.0  96,800.0  96,533.3  98,333.3  99,466.7   \n",
       "\n",
       "     2001Q2    2001Q3    2001Q4    ...       2015Q3    2015Q4    2016Q1  \\\n",
       "0 162,466.7 168,466.7 171,100.0    ...    213,733.3 215,500.0 217,700.0   \n",
       "1  78,700.0  78,700.0  78,900.0    ...    101,633.3 102,533.3 102,600.0   \n",
       "2       nan       nan       nan    ...          nan       nan       nan   \n",
       "3       nan       nan       nan    ...          nan       nan       nan   \n",
       "4 101,333.3 103,200.0 101,866.7    ...    123,200.0 124,033.3 124,866.7   \n",
       "\n",
       "     2016Q2    2016Q3    2016Q4    2017Q1    2017Q2    2017Q3    2017Q4  \n",
       "0 221,433.3 223,966.7 226,033.3 232,566.7 237,466.7 239,466.7 241,533.3  \n",
       "1 104,066.7 105,200.0 105,866.7 106,433.3 108,633.3 110,166.7 111,233.3  \n",
       "2       nan       nan       nan       nan       nan       nan       nan  \n",
       "3       nan       nan       nan       nan       nan       nan       nan  \n",
       "4 124,600.0 123,000.0 124,000.0 127,133.3 129,500.0 131,833.3 132,433.3  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utowns_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to exclude from Housing_dfQ rows that are present in Utowns frame (to get Non-university towns).\n",
    "In order to achieve it I will add 'ones_housing' and 'ones_utowns' column to Housign_dfQ and Utowns data frames correspondingly and then merge those two datasets and choose only those records that have NaN values in 'ones_Utowns' column (so I will exclude records that were in Utowns and not in Housing_dfQ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding dummy columns with ones - it will be used to exclude towns from Utowns \n",
    "### that are in Housing_dfQ frame\n",
    "\n",
    "Housing_dfQ.columns = Housing_dfQ.columns.map(str)\n",
    "Housing_dfQ[\"ones_housing\"] = 1\n",
    "Utowns['ones_utowns'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2000Q1', '2000Q2', '2000Q3', '2000Q4', '2001Q1', '2001Q2', '2001Q3',\n",
       "       '2001Q4', '2002Q1', '2002Q2', '2002Q3', '2002Q4', '2003Q1', '2003Q2',\n",
       "       '2003Q3', '2003Q4', '2004Q1', '2004Q2', '2004Q3', '2004Q4', '2005Q1',\n",
       "       '2005Q2', '2005Q3', '2005Q4', '2006Q1', '2006Q2', '2006Q3', '2006Q4',\n",
       "       '2007Q1', '2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3',\n",
       "       '2008Q4', '2009Q1', '2009Q2', '2009Q3', '2009Q4', '2010Q1', '2010Q2',\n",
       "       '2010Q3', '2010Q4', '2011Q1', '2011Q2', '2011Q3', '2011Q4', '2012Q1',\n",
       "       '2012Q2', '2012Q3', '2012Q4', '2013Q1', '2013Q2', '2013Q3', '2013Q4',\n",
       "       '2014Q1', '2014Q2', '2014Q3', '2014Q4', '2015Q1', '2015Q2', '2015Q3',\n",
       "       '2015Q4', '2016Q1', '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2',\n",
       "       '2017Q3', '2017Q4', 'ones_housing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Housing_dfQ.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>ones_utowns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Florence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montevallo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State    RegionName  ones_utowns\n",
       "0  Alabama        Auburn            1\n",
       "1  Alabama      Florence            1\n",
       "2  Alabama  Jacksonville            1\n",
       "3  Alabama    Livingston            1\n",
       "4  Alabama    Montevallo            1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utowns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NonUtowns_prices = pd.merge(Housing_dfQ, Utowns, how='left', left_index=True,right_on=['State','RegionName'])\n",
    "NonUtowns_prices = NonUtowns_prices[NonUtowns_prices['ones_utowns'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uratio = Utowns_prices.loc[:,last_rec-1]/Utowns_prices.loc[:,last_bot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NonUratio = NonUtowns_prices.loc[:,str(last_rec-1)]/NonUtowns_prices.loc[:,str(last_bot)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_diff(Uratio, NonUratio):\n",
    "    \n",
    "    t,p = stats.ttest_ind(Uratio,NonUratio,axis=0,nan_policy='omit',equal_var=False)\n",
    "    significance = False\n",
    "    if p < 0.01:\n",
    "        significance = True\n",
    "\n",
    "    less_effected = 'Non-university towns'\n",
    "    if np.mean(Uratio) < np.mean(NonUratio):\n",
    "        less_effected = 'University towns'\n",
    "\n",
    "    return (significance, p, less_effected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = testing_diff(Uratio,NonUratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wald t_test is significant: \t\tTrue\n",
      "p-value equals: \t\t\t0.003819769797750409\n",
      "Less effected by recession are: \tUniversity towns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Wald t_test is significant: \\t\\t{0}\\n'\n",
    "       'p-value equals: \\t\\t\\t{1}\\n'\n",
    "       'Less effected by recession are: \\t{2}\\n'\n",
    "      .format(result[0],result[1],result[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: We need to reject the null hipothesis, that there is no difference between mean Uratio and NonUratio. \n",
    "\n",
    "Mean reduced market loss was lower for University towns in USA during last recession started in 2008.  Difference is significant and there is <0.01 probability of making type I error (rejecting null hipothesis that is actually true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
